{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## merkeltreecommit.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../' )\n",
    "\n",
    "from utils import randombytes as utrd\n",
    "\n",
    "\n",
    "LAMBDA = 256\n",
    "\n",
    "#from Crypto.Hash import SHA3_256 as G\n",
    "import hashlib as G\n",
    "\n",
    "def commit( msgList ):\n",
    "    num = len(msgList)\n",
    "    assert( 2 <= num )\n",
    "    assert( 0==(num&(num-1)) )   # len(msgList) is a power of 2\n",
    "    r = [ utrd.randombytes( LAMBDA//8 ) for i in range(num) ]\n",
    "    mktree = [ [ G.sha3_256( msgList[i]+r[i] ).digest() for i in range(num) ]  ]\n",
    "    while( num > 2 ):\n",
    "        last_layer = mktree[-1]\n",
    "        mktree.append([ G.sha3_256( last_layer[i*2]+last_layer[i*2+1] ).digest() for i in range(num>>1) ])\n",
    "        num = num//2\n",
    "    last_layer = mktree[-1]\n",
    "    rt = G.sha3_256( b''.join([last_layer[0],last_layer[1]]) ).digest()\n",
    "    return rt, r , mktree\n",
    "\n",
    "def open( msg , idx , r , mktree ):\n",
    "    _idx = idx\n",
    "    auth_path = [ msg , r[idx] ]\n",
    "    for layer in mktree :\n",
    "        auth_path.append( layer[idx^1] )\n",
    "        idx = idx//2\n",
    "    return auth_path\n",
    "\n",
    "def batchopen( idxes , mesgs , r , mktree ):\n",
    "    return [ open(mesgs[idx], idx , r , mktree) for idx in idxes ]\n",
    "\n",
    "def verify( rt , idx , auth_path ):\n",
    "    state = G.sha3_256( auth_path[0]+auth_path[1] ).digest()\n",
    "    for i in range(2,len(auth_path)):\n",
    "        if (idx&1) : state = G.sha3_256( auth_path[i]+state ).digest()\n",
    "        else       : state = G.sha3_256( state+auth_path[i] ).digest()\n",
    "        idx = idx//2\n",
    "    return state == rt\n",
    "\n",
    "def batchverify( idxes , rt , auth_paths ):\n",
    "    vv = [ verify(rt,idx,auth_paths[i]) for i,idx in enumerate(idxes) ]\n",
    "    return all(vv)\n",
    "\n",
    "\n",
    "if '__main__' == __name__ :\n",
    "   rt, r , mktree = commit( [ b'123' , b'456' , b'789' , b'012' ] )\n",
    "   auth_path = open( b'012' , 3 , r , mktree )\n",
    "   print( \"PASS?\" , verify( rt , 3 , auth_path ) )\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## fir_code.py\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../' )\n",
    "\n",
    "# defining gf\n",
    "from utils import gf2192 as gf\n",
    "\n",
    "# the commit scheme\n",
    "from commit import merkeltreecommit as mt\n",
    "\n",
    "# hash for challenges\n",
    "from utils import hash as H\n",
    "\n",
    "\n",
    "def _dummy( *params ) : return None\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "def ldt_n_commit( f_length ):\n",
    "    i = 0\n",
    "    while( f_length > 2 ):\n",
    "        i = i+1\n",
    "        f_length = f_length//2\n",
    "    return i-1\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "def ldt_commit_phase( vi , poly_len , h_state , RS_rho=8 , RS_shift=1<<63, verbose = 1 ):\n",
    "    if 1 == verbose : dump = print\n",
    "    else : dump = _dummy\n",
    "    assert 0==(poly_len&(poly_len-1)) , 'poly_len is not a power of 2'\n",
    "    assert len(vi)==poly_len*RS_rho   , 'RS_rho * poly_len != len(vi)'\n",
    "\n",
    "    commits = []\n",
    "    mktrees = []\n",
    "\n",
    "    dump( f\"rho: {RS_rho}, offset: {hex(RS_shift)}\" )\n",
    "    dump( f\"|original poly| : {poly_len}\")\n",
    "    dump( \"\\n### commit phase ###\" )\n",
    "    dump( f\"Assume the evaluate on [{hex(RS_shift)},|{poly_len}|x{RS_rho}) has been committed.\" )\n",
    "    dump( \"|v0|:\" , len(vi) )\n",
    "    i = 0\n",
    "    offset = RS_shift\n",
    "    while( 2 < poly_len ):\n",
    "        dump( f\"iteration {i}: update : [{poly_len}] -> [{poly_len//2}]:\" )\n",
    "        xi = gf.from_bytes( H.gen( h_state , bytes([3+i,1]) )[:gf.GF_BSIZE] )\n",
    "        dump( f\"derive new challenge xi <- H(h_state||{3+i}||1) : {hex(xi)}\" )\n",
    "        dump( f\"deriving new polynomial of length [{poly_len//2}]\" )\n",
    "\n",
    "        #dump( f\"v{i-1}: \" , list(map(hex,vi)) )\n",
    "        dump( f\"ibtfy_1( |v{i}|:{len(vi)} , {hex(offset)}) ->\" )\n",
    "        vi = gf.ibtfy_1( vi , offset )\n",
    "        #dump( f\"v{i}: \" , list(map(hex,vi)) )\n",
    "        vi_e = vi[::2]\n",
    "        vi_o = vi[1::2]\n",
    "        vi = [ vi_e[j]^gf.mul(vi_o[j],xi) for j in range(len(vi_e)) ]\n",
    "        dump( f\"xi:{hex(xi)} * |vi|:{len(vi)} ->\" )\n",
    "        #dump( f\"v{i}: \" , list(map(hex,vi)) )\n",
    "        dump( f\"evaluated values generated by 1 stage of ibtfy  [{len(vi)}]\" )\n",
    "        offset = offset >> 1\n",
    "        poly_len = poly_len//2\n",
    "        i = i+1\n",
    "        if poly_len <= 2 : break\n",
    "\n",
    "        mesg = [ gf.to_bytes(vi[j]) + gf.to_bytes(vi[j+1]) for j in range(0,len(vi),2) ]\n",
    "        root , randomness , tree = mt.commit( mesg )\n",
    "        mktrees.append( (root,mesg,randomness,tree) )\n",
    "        commits.append( root )\n",
    "        dump( f\"commit evaluated valuse. --> commits[{len(commits)-1}] <- |mesg|: {len(mesg)}\" )\n",
    "        dump( f\"|commits| = {len(commits)}\" )\n",
    "\n",
    "        h_state = H.gen( h_state , gf.to_bytes(xi) , root )\n",
    "        dump( f\"update h_state <- H( h_state|| xi || commit ): {h_state}\" )\n",
    "    #cc = gf.ibtfy_1( vi , offset )     # use btfy_1 for debug only.\n",
    "    #dump( \"ibtfy_1:\" , hex(offset) , [hex(e) for e in cc] )\n",
    "    cc = gf.ifft( vi[:2] , 1 , offset )   # will get the same poly no matter applying ibtfy_1 to whatever pairs. \n",
    "    dump( \"cc:\" , [hex(i) for i in cc ] )\n",
    "    dump( f\"open deg 1 poly: {hex(cc[0])} + x* {hex(cc[1])}\" )\n",
    "    d1poly = gf.to_bytes(cc[0]) + gf.to_bytes(cc[1])\n",
    "    h_state = H.gen( gf.to_bytes(xi) , d1poly )\n",
    "    dump( f\"update h_state <- H( xi || c0 || c1 ): {h_state}\" )\n",
    "    return commits , d1poly , mktrees , h_state\n",
    "\n",
    "\n",
    "\n",
    "def ldt_query_phase( f_length , mktrees, h_state , Nq , RS_rho=8 , verbose = 1 ):\n",
    "    if 1 == verbose : dump = print\n",
    "    else : dump = _dummy\n",
    "    assert Nq < 256 , \"need to modify hash inputs if supporting >= 256 queries.\"\n",
    "\n",
    "    dump( \"\\n### query phase ###\" )\n",
    "    dump( f\"queries = [ H.gen(h_state , {3+ldt_n_commit(f_length)+1} , j )  for j in range(1,{Nq+1})]\")\n",
    "    queries = [ H.gen(h_state,bytes( [ 3+ldt_n_commit(f_length)+1 , j ] ))[:4] for j in range(1,Nq+1) ]   # use 32 bits of hash results only\n",
    "    idx_mask = (RS_rho*f_length//2)-1\n",
    "    queries = [ int.from_bytes(e,'little')&idx_mask for e in queries ]\n",
    "    _queries = list(queries)\n",
    "    dump( f\"Queries: [{len(queries)}], {queries}\" )\n",
    "\n",
    "    # no need to open valuse of f_0\n",
    "    queries = [ q//2 for q in queries ]\n",
    "\n",
    "    open_mesgs = []\n",
    "    j = 0\n",
    "    for root , all_mesg, randomness, tree in mktrees :\n",
    "        dump( f\"open iteration: {j}\" )\n",
    "        open_mesgs.append( mt.batchopen(queries,all_mesg,randomness,tree) )\n",
    "        dump( f\"proof len:[{len(open_mesgs)}] : auth path len:{len(open_mesgs[-1][0])}\" )\n",
    "        queries = [ q//2 for q in queries ]\n",
    "        j = j+1\n",
    "    return open_mesgs , _queries\n",
    "\n",
    "\n",
    "def ldt_gen_proof( f0 , h_state , Nq = 26 , RS_rho = 8 , verbose = 1 ):\n",
    "    if 1 == verbose : dump = print\n",
    "    else : dump = _dummy\n",
    "\n",
    "    RS_shift = 1<<63\n",
    "    v0 = gf.fft( f0 , RS_rho , RS_shift )\n",
    "    dump( f\"do a redundent commit for v_f0 here for checking correctness\" )\n",
    "    mesg0 = [ gf.to_bytes(v0[j]) + gf.to_bytes(v0[j+1]) for j in range(0,len(v0),2) ]\n",
    "    rt0 , rd0 , tree0 = mt.commit( mesg0 )   # first commit\n",
    "\n",
    "    commits , d1poly , mktrees , h_state = ldt_commit_phase( v0 , len(f0) , h_state , RS_rho , RS_shift , verbose )\n",
    "    open_mesgs , queries = ldt_query_phase( len(f0) , mktrees , h_state , Nq , RS_rho , verbose )\n",
    "\n",
    "    proof = [rt0]\n",
    "    proof.extend( commits )\n",
    "    proof.append( d1poly )\n",
    "    proof.extend( open_mesgs )\n",
    "    proof.append( mt.batchopen(queries,mesg0,rd0,tree0) )  # opened messages of first commit\n",
    "    return proof\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "\n",
    "def ldt_recover_challenges( _poly_len , h_state , commits , d1poly , Nq , RS_rho = 8 , verbose = 1 ):\n",
    "    if 1 == verbose : dump = print\n",
    "    else : dump = _dummy\n",
    "\n",
    "    dump( \"######## recovery hash state and challenges ########\" )\n",
    "    poly_len = _poly_len\n",
    "    i = 0\n",
    "    xi = []\n",
    "    while( 2 < poly_len ):\n",
    "        dump( f\"iteration {i}: [{poly_len}] -> [{poly_len//2}]:\" )\n",
    "        xi.append( gf.from_bytes( H.gen( h_state , bytes([3+i,1]) )[:gf.GF_BSIZE] ) )\n",
    "        dump( f\"derive new challenge xi <- H(h_state||{3+i}||1) : {hex(xi[-1])}\" )\n",
    "        dump( f\"new polynomial length [{poly_len//2}]\" )\n",
    "        poly_len = poly_len//2\n",
    "        if poly_len <= 2 : break\n",
    "        dump( f\"mt.root = commits[{i}] = \" ,  commits[i] )\n",
    "        h_state = H.gen( h_state , gf.to_bytes(xi[i]) , commits[i] )\n",
    "        dump( f\"update h_state <- H( h_state|| xi || commit ): {h_state}\" )\n",
    "        i = i+1\n",
    "    h_state = H.gen( gf.to_bytes(xi[-1]) , d1poly )\n",
    "    dump( f\"update h_state <- H( xi || deg1poly ): {h_state}\" )\n",
    "\n",
    "    dump( \"\\n### query phase ###\" )\n",
    "    dump( f\"queries = [ H.gen(h_state , {3+i+1}=={3+ldt_n_commit(_poly_len)+1} , j )  for j in range(1,{Nq+1})]\")\n",
    "    queries = [ H.gen(h_state,bytes( [ 3+i+1 , j ] ))[:4] for j in range(1,Nq+1) ]\n",
    "    idx_mask = (RS_rho*_poly_len//2)-1\n",
    "    queries = [ int.from_bytes(e,'little')&idx_mask for e in queries ]\n",
    "    dump( f\"Queries: [{len(queries)}], {queries}\" )\n",
    "    return xi , queries\n",
    "\n",
    "\n",
    "\n",
    "def ldt_verify_proof( commits , d1poly , first_mesgs , open_mesgs , xi , queries , RS_shift=1<<63 , verbose = 1 ):\n",
    "    if 1 == verbose : dump = print\n",
    "    else : dump = _dummy\n",
    "\n",
    "    dump( \"#### check linear relations and opened commit ######\" )\n",
    "    offset = RS_shift\n",
    "    j = 0\n",
    "    # check first_mesgs\n",
    "    if True :\n",
    "        # check linear relations\n",
    "        dump( f\"check linear relations:\" )\n",
    "        mesg      = first_mesgs   # [ path[0] for path in first_mesgs ]\n",
    "        next_mesg = [ path[0] for path in open_mesgs[0] ]\n",
    "        verify_j  = [ _check_linear_relation(mesg[i],next_mesg[i],q,xi[j],offset) for i,q in enumerate(queries) ]\n",
    "        dump( f\"check linear relations:\" , all(verify_j) )\n",
    "        if not all(verify_j) : return False\n",
    "        queries = [ q//2 for q in queries ]\n",
    "        offset >>= 1\n",
    "        j = j+1\n",
    "\n",
    "    for idx,auths in enumerate(open_mesgs) :\n",
    "        dump( f\"open iteration: {j}\" )\n",
    "        dump( f\"auths[{len(auths[0])}]: Nbyte: \", sum( map( len,auths[0]) ) )\n",
    "        if not mt.batchverify( queries , commits[j-1] , auths ) :\n",
    "            dump(\"batchverify() fails\")\n",
    "            return False\n",
    "        else : dump(\"oepned mesgs are verified.\")\n",
    "\n",
    "        # check linear relations\n",
    "        mesg = [ path[0] for path in auths ]\n",
    "        if idx == len(open_mesgs)-1 : break\n",
    "        dump( f\"check linear relations [{idx}]:\" )\n",
    "        next_mesg = [ path[0] for path in open_mesgs[idx+1] ]\n",
    "        verify_j  = [ _check_linear_relation(mesg[i],next_mesg[i],q,xi[j],offset) for i,q in enumerate(queries) ]\n",
    "        dump( f\"check linear relations [{idx}]:\" , all(verify_j) )\n",
    "        if not all(verify_j) : return False\n",
    "        queries = [ q//2 for q in queries ]\n",
    "        offset >>= 1\n",
    "        j = j+1\n",
    "    # check deg 1 poly\n",
    "    verify_j = [ _check_deg1poly_linear_relation(mesg[i],d1poly,q,xi[-1],offset) for i,q in enumerate(queries) ]\n",
    "    dump( f\"check last linear relations (with the d1poly):\" , all(verify_j) )\n",
    "    if not all(verify_j) : return False\n",
    "    return True\n",
    "\n",
    "def _check_linear_relation( mesgj1 , mesgj0 , idx , xi , offset ) :\n",
    "    new_j0 = gf.from_bytes_x2( mesgj0 )\n",
    "    org_j1 = gf.from_bytes_x2( mesgj1 )\n",
    "    org_j0 = gf.ibtfy_1( org_j1 , offset^(idx<<1) )\n",
    "    cc1 = org_j0[0] ^ gf.mul( org_j0[1] , xi )\n",
    "    return new_j0[idx&1] == cc1\n",
    "\n",
    "def _check_deg1poly_linear_relation( mesgjm1 , d1poly , idx , xi , offset ) :\n",
    "    m0 = gf.fft( gf.from_bytes_x2(d1poly) , 1 , (offset>>1)^(idx^(idx&1)) )\n",
    "    return _check_linear_relation( mesgjm1 , gf.to_bytes(m0[0])+gf.to_bytes(m0[1]) , idx , xi , offset )\n",
    "\n",
    "\n",
    "def ldt_verify( proof , _poly_len , h_state , Nq = 26 , RS_rho = 8 , verbose = 1 ):\n",
    "    n_commits = ldt_n_commit( _poly_len )\n",
    "    first_commit = proof[0]\n",
    "    commits     = proof[1:1+n_commits]\n",
    "    d1poly      = proof[1+n_commits]\n",
    "    open_mesgs  = proof[2+n_commits:2+n_commits+n_commits]\n",
    "    first_mesgs = proof[2+n_commits+n_commits]\n",
    "    xi, queries = ldt_recover_challenges(_poly_len,h_state,commits,d1poly,Nq, RS_rho, verbose )\n",
    "\n",
    "    if not mt.batchverify( queries , first_commit , first_mesgs ) : return False\n",
    "\n",
    "    return ldt_verify_proof(commits,d1poly,[path[0] for path in first_mesgs],open_mesgs,xi,queries,1<<63,verbose)\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
